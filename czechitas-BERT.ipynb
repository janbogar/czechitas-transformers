{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janbogar/czechitas-transformers/blob/main/czechitas-BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COdcar5UEot5"
      },
      "source": [
        "# Transformers for text processing\n",
        "\n",
        "Transformers are neural networks that changed how we model sequential data.\n",
        "\n",
        "There are many kinds of data that are sequential in nature, for example time series, but i.e. text is also just a sequence of words.\n",
        "\n",
        "State of the art in these areas used to be recurrent neural networks. They work by taking as an input not just an item in the sequence, but also the output of the network on the previous item. This way, the output of the network can contain the memmory of what happened previously.\n",
        "\n",
        "The problem with recurrent neural networks was difficulty of training them in parallel. They also had trouble learning relationships between words that were far away from each other.\n",
        "\n",
        "Transformers work quite differently. All of the sequence is shown to the network at once, and a special architecture called attention head (transformers usually have multiple) predict to which parts of sentence should the network pay attention when processing each word.\n",
        "\n",
        "Famous transformer-based language models are e.g. BERT and GPT3, but there are many more variants, such as RoBERTa, ALBERT, or ELECTRA.\n",
        "\n",
        "# Model\n",
        "In this notebook we will use BERT model trained and published by researches at  West Bohemia University. The model is called Czert and the authors experimented with it on many tasks:\n",
        " - Sequence Classification (**Sentiment Classification**, Multi-label Document Classification)\n",
        " - Sequence Pair Classification (Semantic Text Similarity)\n",
        " -Token Classification (Morphological Tagging, Named Entity Recognition,\n",
        "Semantic Role Labeling)\n",
        "\n",
        "The model:\n",
        "https://huggingface.co/UWB-AIR/Czert-B-base-cased\n",
        "\n",
        "The paper:\n",
        "https://arxiv.org/pdf/2103.13031.pdf\n",
        "\n",
        "# Sentiment analysis\n",
        "\n",
        "In this notebook, we will use the model trained specifically for sentiment analysis. In sentiment analysis, model attempts to classify short texts (oftne social media statuses or customer reviews) as either positive, negative or neutral.\n",
        "\n",
        "Thee authors published two versions of the model, one trained on reviews from www.csfd.cz and other trained on facebook statuses. Both datasets are available on their webpage.\n",
        "\n",
        "The authors claim, that this model had F1 score of\n",
        "77%  on CSFD data and 85% percent on FB data, which they claim are better than the state of the art before this model.\n",
        "F1 score is hard to interpret without knowledge of precission and recall metrics, but for now, let's just say it corresponds somehow to the accuracy of the model.\n",
        "\n",
        "If the model has 75% accuracy, it still makes an error in one quarter of cases. That means that there is still a huge potential for error.\n",
        "\n",
        "In following cells, we will download this model and try to use it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbEbmQinG2OY"
      },
      "source": [
        "## Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 384,
      "metadata": {
        "id": "uJMC7riyHlHt"
      },
      "outputs": [],
      "source": [
        "!pip install certifi\n",
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TIoBmL3G72S"
      },
      "source": [
        "**!! Restart runtime after installing !!**\n",
        "\n",
        "Go to the top of the page, press 'Runtime\" and select \"Restart runtime\".\n",
        "\n",
        "## Download model\n",
        "There are two variants of the model, we will download the one trained on FB data and unzip it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 385,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_i4GED7la5y2",
        "outputId": "b3bf1ec5-9fef-4cd1-f84e-8be5eb1da502"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-11-29 11:34:07--  https://air.kiv.zcu.cz/public/CZERT-B_fb.zip\n",
            "Resolving air.kiv.zcu.cz (air.kiv.zcu.cz)... 147.228.63.35\n",
            "Connecting to air.kiv.zcu.cz (air.kiv.zcu.cz)|147.228.63.35|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 406510308 (388M) [application/zip]\n",
            "Saving to: ‚ÄòCZERT-B_fb.zip.2‚Äô\n",
            "\n",
            "CZERT-B_fb.zip.2    100%[===================>] 387.68M  23.9MB/s    in 20s     \n",
            "\n",
            "2022-11-29 11:34:28 (19.7 MB/s) - ‚ÄòCZERT-B_fb.zip.2‚Äô saved [406510308/406510308]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "#!wget https://air.kiv.zcu.cz/public/CZERT-B_csfd.zip\n",
        "!wget https://air.kiv.zcu.cz/public/CZERT-B_fb.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 386,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygk6MRCIa--G",
        "outputId": "47342162-3c69-4749-fd0c-2198730345f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  CZERT-B_csfd.zip\n",
            "replace CZERT-B_csfd_BS-14_EC-12_LR-0-0000200_LEN-512_SCH-linear_wrp_CPU-False_TRAIN-True_CUST_LAYER-False_BINARY-False_2020-12-06_10-30_07-494882_F1-0.8467/config.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip CZERT-B_fb.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e423bsPjKsZm"
      },
      "source": [
        "# Load the model\n",
        "This model is implemented as a HuggingFace transformer. \n",
        "This means they have a very convenient API and can be easily loaded and reused.\n",
        "I highly recommend their course at:\n",
        "https://huggingface.co/course/chapter1/1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 387,
      "metadata": {
        "id": "vyrXlWYEHyHb"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, BertForSequenceClassification\n",
        "import tensorflow\n",
        "\n",
        "#model_path=\"CZERT-B_csfd_BS-14_EC-12_LR-0-0000200_LEN-512_SCH-linear_wrp_CPU-False_TRAIN-True_CUST_LAYER-False_BINARY-False_2020-12-06_10-30_07-494882_F1-0.8467/\"\n",
        "model_path=\"CZERT-B_fb_BS-32_EC-12_LR-0-0000020_LEN-64_SCH-linear_wrp_CPU-True_TRAIN-True_CUST_LAYER-False_BINARY-False_2020-11-30_13-00_40-335326_F1-0.7598\"\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXDOi4ZOLTay"
      },
      "source": [
        "## What is a tokenizer\n",
        "\n",
        "Neural networks accept as an input vectors or matrices of numbers, so we need to turn texts, that wee want to input into the model, into numbers.\n",
        "\n",
        "Tokenizer is a program that does that. It splits the data into tokens and then assigns each token a number.\n",
        "\n",
        "How to best tokenize text is not a simple question.\n",
        "Transformers usually use sub-word tokenization. Here is an example:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 395,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C29Q_Bn3LSnu",
        "outputId": "85ff4575-2aba-42e1-d1c5-2e5ef16deb64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tokens: '[CLS]' 'za' 'hory' ',' 'za' 'dol' '##y' ',' 'me' 'zlat' '##e' 'par' '##oh' '##y' '[SEP]'\n",
            "encoding:  [2, 1967, 12378, 16, 1967, 10864, 1036, 16, 2913, 7218, 1011, 2667, 2596, 1036, 3]\n"
          ]
        }
      ],
      "source": [
        "sentence = \"Za hory, za doly, m√© zlat√© parohy\"\n",
        "sentence_tokens = [\"[CLS]\"] + tokenizer.tokenize(sentence) + [\"[SEP]\"]\n",
        "sentence_encoding=tokenizer.encode(sentence)\n",
        "print(\"tokens:\" ,\" \".join([f\"\\'{i}\\'\" for i in sentence_tokens]))   \n",
        "print(\"encoding: \",sentence_encoding)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZJQL6rHMe7o"
      },
      "source": [
        "The tokenizer split some words and added special tokens and marks:\n",
        " - `[CLS]` token is always added at the start of text. Transformer outputs one vector per each token, and the vector for `[CLS]` token is used for classification of whole sentences\n",
        "\n",
        "- `[SEP]` token: transformers are also trained on tasks inlcuding relationship of multiple texts. In that case, texts are separated by this special token.\n",
        "\n",
        "- `[PAD]` token was not used in this case, but if there is a need to make multiple sequences the same length, the unused space is filled with `[PAD]` tokens.\n",
        "\n",
        "- `##oh` token: the word `parohy` was split into tokens `par`,`oh` and `y`. To signify that the tokens `oh` and `y` were not  at the start of the word, they are prepended with `##`\n",
        "\n",
        "After splitting the text and adding special tokens, every token is turned into a number, based on it's position in the vocabulary- the document containing all tokens known to the document. If some token is unknown, it's replaced with a special token `[UNK]`. This file was downloaded with the model, and in this case contains one word per line, so if we want to see how many words it contains, we just count the lines in it:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 399,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uOVoCLgPBur",
        "outputId": "438510ea-cd6e-4436-f8a0-5f70b07294c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30000 CZERT-B_fb_BS-32_EC-12_LR-0-0000020_LEN-64_SCH-linear_wrp_CPU-True_TRAIN-True_CUST_LAYER-False_BINARY-False_2020-11-30_13-00_40-335326_F1-0.7598/vocab.txt\n"
          ]
        }
      ],
      "source": [
        "!wc -l CZERT-B_fb_BS-32_EC-12_LR-0-0000020_LEN-64_SCH-linear_wrp_CPU-True_TRAIN-True_CUST_LAYER-False_BINARY-False_2020-11-30_13-00_40-335326_F1-0.7598/vocab.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xaZy7fEPP-E"
      },
      "source": [
        "Here are the last 10 tokens in the vocabulray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 403,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGXt5PTpPJKK",
        "outputId": "68eba2f7-6191-4f7f-df5a-d240f4a046d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "z√°chran√°≈ô\n",
            "zahr√°la\n",
            "repr\n",
            "Britsk√°\n",
            "stƒõ≈æe\n",
            "izp\n",
            "≈ôe≈°√≠me\n",
            "##v√°≈ô√≠\n",
            "##nat√Ω\n",
            "Jerem\n"
          ]
        }
      ],
      "source": [
        "! tail -n 10 CZERT-B_fb_BS-32_EC-12_LR-0-0000020_LEN-64_SCH-linear_wrp_CPU-True_TRAIN-True_CUST_LAYER-False_BINARY-False_2020-11-30_13-00_40-335326_F1-0.7598/vocab.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56YW0johPDa5"
      },
      "source": [
        "# Using the model\n",
        "\n",
        "Now that we know how to preprocess text, let's try the model on some examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "964a4mMdTxTj",
        "outputId": "66ed8451-1604-493e-d1dd-c04e97a7e578"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw sentences:\n",
            " ['Pivo je skvƒõl√Ω', 'Pivo p≈ô√≠≈°ernƒõ p√°chne, fuj', 'Nic extra, d√°vam tomuhle pivu 50 procent']\n",
            "\n",
            "Input of the model after tokenization:\n",
            " {'input_ids': tensor([[    2, 10671,  1955, 15584,  3312,     3,     0,     0,     0,     0,\n",
            "             0,     0,     0],\n",
            "        [    2, 10671, 10769,  9930,  2121,  2371,  1928,  2121,    16, 11293,\n",
            "          1026,     3,     0],\n",
            "        [    2,  2806,  7717,    16, 10203,  2058,  2555,  3045,  8828,  1025,\n",
            "          3784,  2662,     3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
            "\n",
            "Output of the model:\n",
            " SequenceClassifierOutput(loss=None, logits=tensor([[-2.2228,  2.8640, -0.0896],\n",
            "        [ 3.1193, -1.7482, -1.2261],\n",
            "        [ 2.9125, -1.9394, -0.6491]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
          ]
        }
      ],
      "source": [
        "test_strings = [\"Pivo je skvƒõl√Ω\",\"Pivo p≈ô√≠≈°ernƒõ p√°chne, fuj\",\"Nic extra, d√°vam tomuhle pivu 50 procent\"]\n",
        "\n",
        "print(\"Raw sentences:\\n\",test_strings)\n",
        "tokenized_inputs = tokenizer(test_strings, return_tensors=\"pt\", padding=True)\n",
        "print(\"\\nInput of the model after tokenization:\\n\", tokenized_inputs)\n",
        "\n",
        "outputs = model(**tokenized_inputs)\n",
        "print(\"\\nOutput of the model:\\n\", outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1boirDMPous"
      },
      "source": [
        "The output of the model contains a matrix of numbers called logits.\n",
        "Logits are numbers between -infinity and +infinity that represent probability. They can be turned into probability by a softmax function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vE2ch4Pei4Zm",
        "outputId": "b81a5afa-f1b3-4e0d-cebc-2b43e4eb8582"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[0.0058, 0.9449, 0.0493],\n",
              "        [0.9798, 0.0075, 0.0127],\n",
              "        [0.9651, 0.0075, 0.0274]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "execution_count": 198,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.nn.functional import softmax\n",
        "softmax(outputs.logits)  #turn into probabilities (so they are between 0 and 1 and sum into 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBzXV_p0Rz70"
      },
      "source": [
        "Each row in this matrix is prediction for one input text. There are three numbers for each text:\n",
        " - probabbility of text being negative\n",
        " - probabbility of text being positive\n",
        " - probabbility of text being neutral\n",
        "\n",
        "You can check yourself that they add to 1.\n",
        "\n",
        "\n",
        "We will gather all of this code into one function, that will accept a list of texts and will make a prediction for each one.\n",
        "I also wrote a function that will print the prediction nicely."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 426,
      "metadata": {
        "id": "QbK7Ao-WeQF_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "id2label={0:\"negative\",1:\"positive\",2:\"neutral\"}\n",
        "label2id={v:k for k,v in id2label.items()}\n",
        "\n",
        "def get_predictions(texts):\n",
        "  for text in texts:\n",
        "    tokens=tokenizer(text, return_tensors=\"pt\",truncation=\"only_first\",max_length=512)\n",
        "    model_output=model(**tokens)\n",
        "    probabilities=softmax(model_output.logits[0],dim=0).detach().numpy()\n",
        "    highest_probability=np.argmax(probabilities)\n",
        "    yield {\"text\":text,                                                          # input text\n",
        "           \"probabilities\":{k:probabilities[v] for k,v in label2id.items()},     # probabilities of each class (neegative,positive and neutral)\n",
        "           \"prediction\":id2label[highest_probability],                           # prediction: the label of the class with highest probability\n",
        "           \"prediction_confidence\":probabilities[highest_probability]}           # prediction confidence: the probability of the class with the highest probability\n",
        "\n",
        "def print_predictions(predictions):\n",
        "   for i in predictions:\n",
        "       print(f\"{i['prediction']} ({i['prediction_confidence']:.2f}): \\\"{i['text']}\\\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 419,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImBe0q5JluG9",
        "outputId": "14ab3251-d23f-448b-e718-ec5687b0cf23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "positive (0.93): \"tohle je skvele, nejradeji bych to delal cely den\"\n",
            "negative (0.98): \"je to hrozna otrava, nejradeji bych to zakazal\"\n",
            "neutral (0.70): \"davam 50 procent, neurazi\"\n"
          ]
        }
      ],
      "source": [
        "example_texts=[\"tohle je skvele, nejradeji bych to delal cely den\",\"je to hrozna otrava, nejradeji bych to zakazal\",\"davam 50 procent, neurazi\"]\n",
        "\n",
        "print_predictions(get_predictions(example_texts))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GejyBob2mv-k"
      },
      "source": [
        "## Excercise 1\n",
        "\n",
        "Use the code in the previous sentence to find sentences that will fool the model in these ways:\n",
        " - they will output negative if the sentence is positive\n",
        " - they will output positive if the sentence is negative\n",
        " - they will output neutral if the sentence is either positive or negative\n",
        " - they will output positive or negative if the sentence is neutral\n",
        "\n",
        "Which is hardest. Which is harder, to fool the model if the text is long or short?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 345,
      "metadata": {
        "id": "TFeIzKf7n5dc"
      },
      "outputs": [],
      "source": [
        "#do the excercise!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsW-iTmfXold"
      },
      "source": [
        "# Let's watch politicians\n",
        "\n",
        "Let's use this model for good: monitoring politicians.\n",
        "\n",
        "We can try to classify their posts on social media as positive, negative and neutral. Maybe that can tell us us something about their authors.\n",
        "\n",
        "# Where to get data\n",
        "\n",
        "Luckily, there is a webpage called Hlidaci Statu, which collected a huge dataset of social media interractions of czech politicians (and many other usefull datasets).\n",
        "\n",
        "In the next few cells, we will write a function that will download their data.\n",
        "\n",
        "To acces it though, you need to register with your google account.\n",
        "\n",
        "Here are the steps:\n",
        " - Go to https://www.hlidacstatu.cz/Identity/Account/Login?returnUrl=/\n",
        " - Login with google account\n",
        " - After loging in, click on your profile (top right corner)\n",
        " - In the menu at left, click on \"API klic\"\n",
        " - Copy the key value into the next cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 346,
      "metadata": {
        "id": "Qvbtaaz_uGJj"
      },
      "outputs": [],
      "source": [
        "auth_key=\"blablabla here is your API key\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWTe480AdXo_"
      },
      "source": [
        "This code uses the requests library to access the web API of Hlidaci Statu and downloads one page of posts of Petr Fiala he made on Facebook.\n",
        "Pay attention to the params argument.\n",
        "\n",
        "We print first 10 texts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 347,
      "metadata": {
        "id": "aqTMnxDkX31X"
      },
      "outputs": [],
      "source": [
        "import requests as rq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 436,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKRYgTxmuCUQ",
        "outputId": "43d6c778-ed64-4a57-f886-aa67821e9081"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['',\n",
              " 'Dƒõkuji za jednomyslnou nominaci na p≈ôedsedu ODS deleg√°t≈Øm jihoƒçesk√© ODS. Gratuluji Martinu Kubovi k jasn√©mu obh√°jen√≠ pozice p≈ôedsedy regionu. Jihoƒçesk√° ODS z√≠skala v ned√°vn√Ωch parlamentn√≠ch volb√°ch nadpr≈Ømƒõrn√Ω v√Ωsledek. V Janu Zahradn√≠kovi a novƒõ i v Janu Bauerovi maj√≠ jihoƒçe≈°t√≠ voliƒçi v√Ωborn√© z√°stupce v Poslaneck√© snƒõmovnƒõ, kte≈ô√≠ dob≈ôe reprezentuj√≠ na≈°i politiku.',\n",
              " 'Dnes se sna≈æ√≠ Listopad 89 vyu≈æ√≠t ve sv≈Øj prospƒõch r≈Øzn√≠ populist√©, extremist√©, komunist√© a dokonce b√Ωval√≠ agenti StB. Nedovolme jim to. \\n\\nP≈ôipom√≠nejme si, co se tehdy skuteƒçnƒõ dƒõlo, mluvme s lidmi, kte≈ô√≠ si tu dobu pamatuj√≠, kte≈ô√≠ se revoluce aktivnƒõ √∫ƒçastnili. Proto po≈ô√°d√°me s√©rii diskuz√≠ na mnoha m√≠stech na≈°√≠ zemƒõ. \\n\\nR√°d se s V√°mi uvid√≠m nap≈ô√≠klad 9. ≈ô√≠jna v Praze. https://www.ods.cz/30-let-svobody/setkani',\n",
              " '\"Letn√≠ interview\" s moder√°torkou Michaelou ≈†m√≠dovou. Neobvykl√© prost≈ôed√≠ s kr√°sn√Ωm v√Ωhledem na Prahu, ale mluvili jsme hodnƒõ o Brnƒõ a o Moravƒõ. :-) Kromƒõ politiky jsme si pov√≠dali t≈ôeba o italsk√© kuchyni, tenisu, v√≠nƒõ, slivovici, prostƒõ o spoustƒõ p≈ô√≠jemn√Ωch vƒõc√≠. M≈Ø≈æete sledovat dnes veƒçer ve 22:50 na TV Nova.',\n",
              " 'Lipov√° na Dƒõƒç√≠nsku se o v√≠kendu stala leto≈°n√≠ vesnic√≠ roku 2019. Proto jsem dnes telefonicky pogratuloval jej√≠mu starostovi Pavlu Svobodovi. \\n\\nPan starosta v posledn√≠ch komun√°ln√≠ch volb√°ch vedl v Lipov√© kandid√°tku ODS, kter√° zv√≠tƒõzila se ziskem tak≈ôka 60 % hlas≈Ø. Dal≈°√≠ d≈Økaz, ≈æe to v Lipov√© dƒõlaj√≠ dob≈ôe. ;-)']"
            ]
          },
          "execution_count": 436,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response=rq.get(\"https://api.hlidacstatu.cz/Api/v2/datasety/vyjadreni-politiku/hledat\",params={'dotaz':\"server:Facebook AND osobaid:petr-fiala\",\"strana\":1},headers={\"Authorization\":auth_key})\n",
        "results=response.json()[\"results\"]\n",
        "texts=[i[\"text\"] for i in results]\n",
        "texts[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hFLoWJ3d9VN"
      },
      "source": [
        "We can wrap this up as a function.\n",
        "This function downloads 300 latest Facebook posts of a chosen politician from the database.\n",
        "\n",
        "The name of a politician must be lovercased and spaces are exchanged for a `-` sign.\n",
        "\n",
        "So \"andrej-babis\" instead of \"Andrej Babis\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 414,
      "metadata": {
        "id": "rk-DpUfpZxYk"
      },
      "outputs": [],
      "source": [
        "def get_page(name,page):\n",
        "  response=rq.get(\"https://api.hlidacstatu.cz/Api/v2/datasety/vyjadreni-politiku/hledat\",params={'dotaz':f\"server:Facebook AND osobaid:{name}\",\"strana\":{page},\"sort\":\"datum\",\"desc\":1},headers={\"Authorization\":auth_key})\n",
        "  return response.json()\n",
        "\n",
        "def get_texts(name,at_most=300):\n",
        "  \"\"\"\n",
        "  Download 300 newest posts of a politician in the database. Selects only posts made to Facebook.\n",
        "  \"\"\"\n",
        "  current_page=0\n",
        "  texts=[]\n",
        "  \n",
        "  page=get_page(name,current_page)\n",
        "  total_in_database=page[\"total\"]\n",
        "  print(\"total in database: \",total_in_database)\n",
        "\n",
        "  texts+=[i['text'] for i in page[\"results\"]]\n",
        "  print(f\"page: {current_page}, texts_so_far: {len(texts)}\")\n",
        "  \n",
        "  while not (len(texts)>=at_most or len(texts)>=total_in_database):\n",
        "    current_page+=1\n",
        "    page=get_page(name,current_page)\n",
        "    texts+=[i['text'] for i in page[\"results\"]]\n",
        "    print(f\"page: {current_page}, texts_so_far: {len(texts)}\")\n",
        "  \n",
        "  if len(texts)>at_most:\n",
        "    texts=texts[:at_most]\n",
        "  return texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmYKyLuGehyk"
      },
      "source": [
        "Let's download the texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 434,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfAvUXttZyNA",
        "outputId": "97a01335-affe-43c6-e819-d8385f066675"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total in database:  10308\n",
            "page: 0, texts_so_far: 25\n",
            "page: 1, texts_so_far: 50\n",
            "page: 2, texts_so_far: 75\n",
            "page: 3, texts_so_far: 100\n",
            "page: 4, texts_so_far: 125\n",
            "page: 5, texts_so_far: 150\n",
            "page: 6, texts_so_far: 175\n",
            "page: 7, texts_so_far: 200\n",
            "page: 8, texts_so_far: 225\n",
            "page: 9, texts_so_far: 250\n",
            "page: 10, texts_so_far: 275\n",
            "page: 11, texts_so_far: 300\n"
          ]
        }
      ],
      "source": [
        "name=\"andrej-babis\"\n",
        "texts=get_texts(name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPKbsuK4fvi4"
      },
      "source": [
        "Now let's use the model to process these texts. The cell can run up to a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 424,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvWw2rio1t96",
        "outputId": "fa9f3d61-8432-4f79-e116-c752f3d65aa2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "processing texts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [01:06<00:00,  4.51it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm   # for a nice progress bar\n",
        "\n",
        "predictions=list(tqdm(get_predictions(texts),total=len(texts),desc=\"processing texts\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 432,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8pGiQJqhIxb",
        "outputId": "d48eecc9-36d8-4f44-f15f-c0e06ee1e75f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "positive (0.53): \"Je Nov√Ω rok. Velk√Ω sv√°tek na≈°√≠ zemƒõ a n√°s v≈°ech. A j√° m√°m nƒõco na srdci ‚ù§Ô∏è\"\n",
            "neutral (0.98): \"Ode mƒõ pro V√°s. M≈Øj neuvƒõ≈ôiteln√Ω rok 2021 ve fotk√°ch. T≈ôeba se tam najdete ‚ù§Ô∏è\"\n",
            "neutral (0.97): \"Kupuju obyt≈à√°k!\"\n",
            "neutral (0.97): \"Kupuju obyt≈à√°k!\"\n",
            "neutral (0.79): \"Je to tady. Kupuju obyt≈à√°k!\"\n"
          ]
        }
      ],
      "source": [
        "print_predictions(predictions[:5])   # the latest posts in the database are from the end of 2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubW54ntjf12h"
      },
      "source": [
        "In the next cell, let's tak a look at probability distribution of confidences of predicted labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 433,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "ezx9XXJX136L",
        "outputId": "746a759c-95aa-4c81-d832-f5720f684481"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7fe2b2aabf90>"
            ]
          },
          "execution_count": 433,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1080x360 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sb\n",
        "import pandas as pd\n",
        "sb.displot(pd.DataFrame(predictions),x=\"prediction_confidence\",col=\"prediction\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQd-x23zib6k"
      },
      "source": [
        "Looks like the model is usually only confident about neutral predictions of Andrej Babis (most such predictions have high confidence) and much less confident about the positive and negagtive predictions.\n",
        "\n",
        "------\n",
        "## Question 1:\n",
        "\n",
        "Is this because of the data (positive and negative statements are written in relatively neutral way, compared to the training data), or is it because of the model (model is somehow biasad towards neutral models)?\n",
        "\n",
        "How could we find out?\n",
        "\n",
        "-------\n",
        "\n",
        "Let's select most positive and most negative statements:\n",
        "\n",
        "------\n",
        "## Question 2:\n",
        "\n",
        "These are the statements where the model was most confident about prediction. Is it the same thing as actually being \"most positive and most negative\".\n",
        "\n",
        "What would we need to do to get these answers from the model?\n",
        "\n",
        "-------\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 365,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cD7c7buU6zsl",
        "outputId": "1ff82b29-4fbb-4547-c364-43cf1ca3b799"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the most positive:  {'text': 'Je tady fajn üö¥\\u200d‚ôÄÔ∏èüòÇ', 'probabilities': {'negative': 0.002989267, 'positive': 0.9914219, 'neutral': 0.0055887965}, 'prediction': 'positive', 'prediction_confidence': 0.9914219}\n",
            "the most negative:  {'text': 'U≈æ to do z√≠tra nevydr≈æ√≠m, tady to m√°te.', 'probabilities': {'negative': 0.9691094, 'positive': 0.003227884, 'neutral': 0.027662616}, 'prediction': 'negative', 'prediction_confidence': 0.9691094}\n"
          ]
        }
      ],
      "source": [
        "print(\"the most positive: \", max([i for i in predictions if i[\"prediction\"]==\"positive\"],key=lambda x: x[\"prediction_confidence\"]))\n",
        "print(\"the most negative: \", max([i for i in predictions if i[\"prediction\"]==\"negative\"],key=lambda x: x[\"prediction_confidence\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_zl2kjdlNdX"
      },
      "source": [
        "Let's look at the overal number of posts that are positive or negative.\n",
        "\n",
        "We will select a threshold of 0.9 as a threshold, above which we trust the model.\n",
        "If the confidence is lower, we leave the post unclassified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 437,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "HKWbPP1cCD6-",
        "outputId": "5a0fb1b3-fa0c-4728-8d54-dba1e79832d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<BarContainer object of 4 artists>"
            ]
          },
          "execution_count": 437,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "threshold=0.9\n",
        "only_confident=[i[\"prediction\"] for i in predictions if i[\"prediction_confidence\"]>threshold]\n",
        "labels,counts=np.unique(only_confident,return_counts=True)\n",
        "counts=list(counts)\n",
        "labels=list(labels)\n",
        "counts+=[len(predictions)-len(only_confident)]\n",
        "labels+=[\"unclassified\"]\n",
        "plt.ylabel(\"counts\")\n",
        "plt.title(name)\n",
        "plt.bar(labels,counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zl0V-U7RlidI"
      },
      "source": [
        "## Question 3\n",
        "What does this plot say?\n",
        "Does it match your expectations?\n",
        "Is the model good enough for us to make conclusions about the author of these posts?\n",
        "\n",
        "## Excercise 2\n",
        "In the next cell, see the results for another politician of your choice. Are they different?\n",
        "Post your resulst (plots, not texts) into the gallery with the name of the politician."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UctFch8-EXAz",
        "outputId": "18334255-ac79-4ccc-9b9f-ebce970f6a64"
      },
      "outputs": [],
      "source": [
        "name=\"jozko-mrkvicka\"\n",
        "texts=get_texts(name)\n",
        "predictions=list(tqdm(get_predictions(texts),total=len(texts),desc=\"processing texts\"))\n",
        "\n",
        "sb.displot(pd.DataFrame(predictions),x=\"prediction_confidence\",col=\"prediction\")\n",
        "plt.show()\n",
        "\n",
        "threshold=0.9\n",
        "only_confident=[i[\"prediction\"] for i in predictions if i[\"prediction_confidence\"]>threshold]\n",
        "labels,counts=np.unique(only_confident,return_counts=True)\n",
        "counts=list(counts)\n",
        "labels=list(labels)\n",
        "counts+=[len(predictions)-len(only_confident)]\n",
        "labels+=[\"unclassified\"]\n",
        "plt.ylabel(\"counts\")\n",
        "plt.title(name)\n",
        "plt.bar(labels,counts)\n",
        "plt.show()\n",
        "\n",
        "print(\"the most positive: \", max([i for i in predictions if i[\"prediction\"]==\"positive\"],key=lambda x: x[\"prediction_confidence\"]))\n",
        "print(\"the most negative: \", max([i for i in predictions if i[\"prediction\"]==\"negative\"],key=lambda x: x[\"prediction_confidence\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transfer learning\n",
        "What if we wanted the model to do something new, e.g.:\n",
        " - make the model better\n",
        " - do something slightly else (e.g.predict positivity score instead of classification)\n",
        "\n",
        "As is, the model obviously understands something about czech language.\n",
        "This knowledge is mostly in the first layers of the model, while the last layers are related more to taking this knowledge and aggregating it to predictions.\n",
        "\n",
        "So we have two options:\n",
        "\n",
        "## Fine tuning:\n",
        "We cut off last few layers of the model, and replace them with the layers that better suits our new needs (e.g. if we wanted more than three classes, we would put a layer that outputs more numbers than 3). If the task doesn't require different architecture, we don't need to do this.\n",
        "\n",
        "And then we train the whole model again on new data.\n",
        "\n",
        "Positives:\n",
        " - best performance\n",
        "Negatives:\n",
        " - the model is huge and slow\n",
        " - the model is hard to train\n",
        "\n",
        "## Embeddinggs:\n",
        "We cut off the last few layers of the model, and use the output of the last layer we left there as input to a completely new model we will train on it.\n",
        "\n",
        "This output of some internal hidden layere of the network is usually called \"embedding\". Since internal layers are usually large, it often has many dimensions (e.g. for transformers it could be 256 or 512). The hope is, that this embedding reflects high level features that summarize the data, but is yet not specific to the task we trained the model on.\n",
        "\n",
        "Negatives:\n",
        " - likely not as good as retraining whole model\n",
        "\n",
        "Positives:\n",
        " - faster training\n",
        " - other good uses of embeddings (e.g. you can search for simmilar records in the dataset by comparing their embeddings mathematically) \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "COdcar5UEot5",
        "KbEbmQinG2OY",
        "2TIoBmL3G72S",
        "zXDOi4ZOLTay"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
